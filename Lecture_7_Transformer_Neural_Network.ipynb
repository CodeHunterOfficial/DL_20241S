{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOixvb80UjXc+OKEkb3rZvA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/DL_20241S/blob/main/Lecture_7_Transformer_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "8zSFqrW05xEW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "WK1 = np.array(\n",
        "    [[1, 0, 1], [0, 1, 0],\n",
        "     [1, 0, 1], [0, 1, 0]])\n",
        "WV1 = np.array(\n",
        "    [[0, 1, 1], [1, 0, 0],\n",
        "     [1, 0, 1], [0, 1, 0]])\n",
        "WQ1 = np.array(\n",
        "    [[0, 0, 0], [1, 1, 0],\n",
        "     [0, 0, 1], [1, 0, 0]])\n",
        "\n",
        "WK2 = np.array(\n",
        "    [[0, 1, 1], [1, 0, 1],\n",
        "     [1, 1, 0], [0, 1, 0]])\n",
        "WV2 = np.array(\n",
        "    [[1, 0, 0], [0, 1, 1],\n",
        "     [0, 0, 1], [1, 0, 0]])\n",
        "WQ2 = np.array(\n",
        "    [[1, 0, 1], [0, 1, 0],\n",
        "     [1, 0, 0], [0, 1, 1]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = np.array([[1, 3, 3, 5], [2.84, 3.99, 4, 6]])\n",
        "K1 = embedding @ WK1\n",
        "#K1 = np.dot(embedding, WK1)\n",
        "print(K1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQK4hncA6FqM",
        "outputId": "1307401a-9667-454c-8ca6-d293485d81ad"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4.   8.   4.  ]\n",
            " [6.84 9.99 6.84]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "V1 = embedding @ WV1\n",
        "print(V1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvH-G-RU6yvW",
        "outputId": "26a65c3c-2a94-4009-ba44-af9f1d2fddee"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6.   6.   4.  ]\n",
            " [7.99 8.84 6.84]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = embedding @ WQ1\n",
        "print(Q1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEnoCraL7Y1a",
        "outputId": "5b1a8c9f-83c6-4441-caa4-bbcef0c9d1e0"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8.   3.   3.  ]\n",
            " [9.99 3.99 4.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores1 = Q1 @ K1.T\n",
        "print(scores1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vU_WoZu_Jk4",
        "outputId": "7a39112d-dda7-4001-da9b-eb0f2a2fef5c"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 68.     105.21  ]\n",
            " [ 87.88   135.5517]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores1 = scores1 / np.sqrt(3)\n",
        "print(scores1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOzeCO6p_ehK",
        "outputId": "811d90b6-b6d0-49ee-b142-965fa9719099"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[39.2598183  60.74302182]\n",
            " [50.73754166 78.26081048]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
        "\n",
        "scores1 = softmax(scores1)\n",
        "print(scores1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paNs4bShAhgW",
        "outputId": "2a8e282c-1f4c-4592-c8f2-ed83be28be79"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4.67695573e-10 1.00000000e+00]\n",
            " [1.11377182e-12 1.00000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention1 = scores1 @ V1\n",
        "print(attention1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_Sp5ylCBAKN",
        "outputId": "fd075dec-6f12-4929-8ab8-41ee2e5f93bb"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7.99 8.84 6.84]\n",
            " [7.99 8.84 6.84]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(x, WQ, WK, WV):\n",
        "    K = x @ WK\n",
        "    V = x @ WV\n",
        "    Q = x @ WQ\n",
        "\n",
        "    scores = Q @ K.T\n",
        "    scores = scores / np.sqrt(3)\n",
        "    scores = softmax(scores)\n",
        "    scores = scores @ V\n",
        "    return scores\n",
        "\n",
        "attention1=attention(embedding, WQ1, WK1, WV1)\n",
        "print(attention1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfuoskvOBme8",
        "outputId": "afa5280e-e62d-4f14-d4fa-ab181b4fd852"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7.99 8.84 6.84]\n",
            " [7.99 8.84 6.84]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention2 = attention(embedding, WQ2, WK2, WV2)\n",
        "print(attention2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DDZqbtQC1B2",
        "outputId": "a743b068-6521-4390-804f-e33f9a424ed4"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8.84 3.99 7.99]\n",
            " [8.84 3.99 7.99]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soft=softmax(((embedding @ WQ2) @ (embedding @ WK2).T) / np.sqrt(3))\n",
        "print(soft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubXsB327Db-p",
        "outputId": "a30830b2-26b4-4a27-ffc3-fefacc797939"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.10613872e-14 1.00000000e+00]\n",
            " [4.95934510e-20 1.00000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(x, WQ, WK, WV):\n",
        "    K = x @ WK\n",
        "    V = x @ WV\n",
        "    Q = x @ WQ\n",
        "\n",
        "    scores = Q @ K.T\n",
        "    scores = scores / 30  # we just changed this\n",
        "    scores = softmax(scores)\n",
        "    scores = scores @ V\n",
        "    return scores\n",
        "\n",
        "attention1 = attention(embedding, WQ1, WK1, WV1)\n",
        "print(attention1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl6_pCX-D4T8",
        "outputId": "dac7f95d-54e8-43a0-c5bd-f50dbf4af1d9"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7.54348784 8.20276657 6.20276657]\n",
            " [7.65266185 8.35857269 6.35857269]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention2 = attention(embedding, WQ2, WK2, WV2)\n",
        "print(attention2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkjetYHPEYJ6",
        "outputId": "8082a72e-0b73-4c7d-908b-a2d8cd83c97b"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8.45589591 3.85610456 7.72085664]\n",
            " [8.63740591 3.91937741 7.84804146]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attentions = np.concatenate([attention1, attention2], axis=1)\n",
        "print(attentions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVfABlj9LmDf",
        "outputId": "1ba863e3-0ba4-4527-c221-a3effc557a75"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7.54348784 8.20276657 6.20276657 8.45589591 3.85610456 7.72085664]\n",
            " [7.65266185 8.35857269 6.35857269 8.63740591 3.91937741 7.84804146]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Просто произвольные значения\n",
        "W = np.array(\n",
        "    [\n",
        "        [0.79445237, 0.1081456, 0.27411536, 0.78394531],\n",
        "        [0.29081936, -0.36187258, -0.32312791, -0.48530339],\n",
        "        [-0.36702934, -0.76471963, -0.88058366, -1.73713022],\n",
        "        [-0.02305587, -0.64315981, -0.68306653, -1.25393866],\n",
        "        [0.29077448, -0.04121674, 0.01509932, 0.13149906],\n",
        "        [0.57451867, -0.08895355, 0.02190485, 0.24535932],\n",
        "    ]\n",
        ")\n",
        "Z = attentions @ W\n",
        "print(Z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucm1nozwMSC7",
        "outputId": "8f4c75e4-f79d-4e6d-ad1a-733b6b027fba"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 11.46394285 -13.18016471 -11.59340253 -17.04387829]\n",
            " [ 11.62608573 -13.47454936 -11.87126395 -17.4926367 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = np.random.randn(4, 8)\n",
        "W2 = np.random.randn(8, 4)\n",
        "b1 = np.random.randn(8)\n",
        "b2 = np.random.randn(4)"
      ],
      "metadata": {
        "id": "FudHIDiqOqvP"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def feed_forward(Z, W1, b1, W2, b2):\n",
        "    return relu(Z.dot(W1) + b1).dot(W2) + b2\n",
        "\n",
        "output_encoder = feed_forward(Z, W1, b1, W2, b2)\n",
        "print(output_encoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWCwECBAO0a5",
        "outputId": "b27e4c91-9723-41c2-9b00-797a728e6856"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-40.81218994 102.60294212 -24.68209298  46.53786689]\n",
            " [-41.22808664 104.77918506 -25.20966077  46.96370499]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Указываем размерности\n",
        "d_embedding = 4\n",
        "d_key = d_value = d_query = 3\n",
        "d_feed_forward = 8\n",
        "n_attention_heads = 2\n",
        "\n",
        "# Функция для выполнения attention механизма\n",
        "def attention(x, WQ, WK, WV):\n",
        "    K = x @ WK  # Умножение входа на матрицу ключей\n",
        "    V = x @ WV  # Умножение входа на матрицу значений\n",
        "    Q = x @ WQ  # Умножение входа на матрицу запросов\n",
        "\n",
        "    scores = Q @ K.T  # Вычисление попарных скалярных произведений между запросами и ключами\n",
        "    scores = scores / np.sqrt(d_key)  # Нормирование на корень из размерности ключа\n",
        "    scores = softmax(scores)  # Применение softmax для получения весов\n",
        "    scores = scores @ V  # Взвешенная сумма значений с учетом полученных весов\n",
        "    return scores\n",
        "\n",
        "# Функция для выполнения механизма multi-head attention\n",
        "def multi_head_attention(x, WQs, WKs, WVs):\n",
        "    attentions = np.concatenate(\n",
        "        [attention(x, WQ, WK, WV) for WQ, WK, WV in zip(WQs, WKs, WVs)], axis=1\n",
        "    )\n",
        "    W = np.random.randn(n_attention_heads * d_value, d_embedding)\n",
        "    return attentions @ W\n",
        "\n",
        "# Функция для выполнения feed-forward сети\n",
        "def feed_forward(Z, W1, b1, W2, b2):\n",
        "    return relu(Z.dot(W1) + b1).dot(W2) + b2\n",
        "\n",
        "# Функция для выполнения блока кодировщика\n",
        "def encoder_block(x, WQs, WKs, WVs, W1, b1, W2, b2):\n",
        "    Z = multi_head_attention(x, WQs, WKs, WVs)  # Применение multi-head attention\n",
        "    Z = feed_forward(Z, W1, b1, W2, b2)  # Применение feed-forward сети\n",
        "    return Z\n",
        "\n",
        "# Функция для создания случайного блока кодировщика\n",
        "def random_encoder_block(x):\n",
        "    # Генерация случайных матриц для запросов, ключей и значений\n",
        "    WQs = [\n",
        "        np.random.randn(d_embedding, d_query) for _ in range(n_attention_heads)\n",
        "    ]\n",
        "    WKs = [\n",
        "        np.random.randn(d_embedding, d_key) for _ in range(n_attention_heads)\n",
        "    ]\n",
        "    WVs = [\n",
        "        np.random.randn(d_embedding, d_value) for _ in range(n_attention_heads)\n",
        "    ]\n",
        "    # Генерация случайных матриц и векторов для feed-forward сети\n",
        "    W1 = np.random.randn(d_embedding, d_feed_forward)\n",
        "    b1 = np.random.randn(d_feed_forward)\n",
        "    W2 = np.random.randn(d_feed_forward, d_embedding)\n",
        "    b2 = np.random.randn(d_embedding)\n",
        "    return encoder_block(x, WQs, WKs, WVs, W1, b1, W2, b2)"
      ],
      "metadata": {
        "id": "SHXCjs5_PkQh"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECi1gayuQBhU",
        "outputId": "72e430b5-5b3b-4297-ded7-e3cf5c9cf8a2"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.   3.   3.   5.  ]\n",
            " [2.84 3.99 4.   6.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reb=random_encoder_block(embedding)\n",
        "print(reb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enImtL8lQzYj",
        "outputId": "569310b1-3ac9-40e9-d7ce-20dee3ada361"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-22.49968495 -46.3947742   31.6252161  -19.87403458]\n",
            " [-22.49968495 -46.3947742   31.6252161  -19.87403458]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder(x, n=6):\n",
        "    for _ in range(n):\n",
        "        x = random_encoder_block(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "enc=encoder(embedding)\n",
        "print(enc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpr45g2XRte2",
        "outputId": "e49f792f-6a38-46b5-d619-5f190f4b6dd8"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[nan nan nan nan]\n",
            " [nan nan nan nan]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-100-85e78fde2c1d>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
            "<ipython-input-100-85e78fde2c1d>:2: RuntimeWarning: invalid value encountered in divide\n",
            "  return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_embedding_Z=(embedding + Z).mean(axis=-1, keepdims=True)\n",
        "print(mean_embedding_Z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPXd3xgYUcYL",
        "outputId": "18ceb324-541b-4262-b560-aac03051fc46"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-4.58837567]\n",
            " [-3.59559107]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "std_embedding_Z=(embedding + Z).std(axis=-1, keepdims=True)\n",
        "print(std_embedding_Z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqFW5bGbVNli",
        "outputId": "ac5828dc-2982-4ff3-9475-27636eeb58f2"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9.92061529]\n",
            " [10.50653019]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def layer_norm(x, epsilon=1e-6):\n",
        "    mean = x.mean(axis=-1, keepdims=True)\n",
        "    std = x.std(axis=-1, keepdims=True)\n",
        "    return (x - mean) / (std + epsilon)\n",
        "\n",
        "def encoder_block(x, WQs, WKs, WVs, W1, b1, W2, b2):\n",
        "    Z = multi_head_attention(x, WQs, WKs, WVs)\n",
        "    Z = layer_norm(Z + x)\n",
        "\n",
        "    output = feed_forward(Z, W1, b1, W2, b2)\n",
        "    return layer_norm(output + Z)\n",
        "\n",
        "L_norm=layer_norm(Z + embedding)\n",
        "print(L_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5JgTNRwWu9-",
        "outputId": "17ed7a25-dc64-47be-c7c8-989ba8acc6e3"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.71887693 -0.56365339 -0.40370747 -0.75151608]\n",
            " [ 1.71909039 -0.56050453 -0.40695381 -0.75163205]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder(x, n=6):\n",
        "    for _ in range(n):\n",
        "        x = random_encoder_block(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "enc_emb=encoder(embedding)\n",
        "print(enc_emb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ3o7i2oXqjf",
        "outputId": "bd0b8621-803b-4cba-e39c-2c87397b026e"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.14690571 -0.07281854 -0.37386515  1.59358941]\n",
            " [-1.14690572 -0.07281854 -0.37386514  1.5935894 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_embedding = 4\n",
        "n_attention_heads = 2\n",
        "\n",
        "E = np.array([[1, 1, 0, 1]])\n",
        "WQs = [np.random.randn(d_embedding, d_query) for _ in range(n_attention_heads)]\n",
        "WKs = [np.random.randn(d_embedding, d_key) for _ in range(n_attention_heads)]\n",
        "WVs = [np.random.randn(d_embedding, d_value) for _ in range(n_attention_heads)]\n",
        "\n",
        "Z_self_attention = multi_head_attention(E, WQs, WKs, WVs)\n",
        "print(Z_self_attention)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnSdwW-IZbO7",
        "outputId": "3e20479f-36db-4cc5-ed6e-e6f46ebbfc34"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.22150133  0.32004543 -3.99199819  0.41807913]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z_self_attention = layer_norm(Z_self_attention + E)\n",
        "print(Z_self_attention)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egvO9-thZ6s5",
        "outputId": "a3a7f474-c7a5-4d29-eca2-23cc6942ea14"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.53433689  0.57716056 -1.73125989  0.61976244]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_decoder_attention(encoder_output, attention_input, WQ, WK, WV):\n",
        "    # В следующих трёх строках и состоит основное различие!\n",
        "    K = encoder_output @ WK    # Обратите внимание, что теперь мы передаём предыдущие выходные данные кодировщика!\n",
        "    V = encoder_output @ WV    # Обратите внимание, что теперь мы передаём предыдущие выходные данные кодировщика!\n",
        "    Q = attention_input @ WQ   # То же, что и для самовнимания\n",
        "\n",
        "    # Остаётся таким же\n",
        "    scores = Q @ K.T\n",
        "    scores = scores / np.sqrt(d_key)\n",
        "    scores = softmax(scores)\n",
        "    scores = scores @ V\n",
        "    return scores\n",
        "\n",
        "\n",
        "def multi_head_encoder_decoder_attention(\n",
        "    encoder_output, attention_input, WQs, WKs, WVs\n",
        "):\n",
        "    # Обратите внимание, что теперь мы передаём предыдущие выходные данные кодировщика!\n",
        "    attentions = np.concatenate(\n",
        "        [\n",
        "            encoder_decoder_attention(\n",
        "                encoder_output, attention_input, WQ, WK, WV\n",
        "            )\n",
        "            for WQ, WK, WV in zip(WQs, WKs, WVs)\n",
        "        ],\n",
        "        axis=1,\n",
        "    )\n",
        "    W = np.random.randn(n_attention_heads * d_value, d_embedding)\n",
        "    return attentions @ W\n",
        "\n",
        "\n",
        "WQs = [np.random.randn(d_embedding, d_query) for _ in range(n_attention_heads)]\n",
        "WKs = [np.random.randn(d_embedding, d_key) for _ in range(n_attention_heads)]\n",
        "WVs = [np.random.randn(d_embedding, d_value) for _ in range(n_attention_heads)]\n",
        "\n",
        "encoder_output = np.array([[-1.5, 1.0, -0.8, 1.5], [1.0, -1.0, -0.5, 1.0]])\n",
        "\n",
        "Z_encoder_decoder = multi_head_encoder_decoder_attention(\n",
        "    encoder_output, Z_self_attention, WQs, WKs, WVs\n",
        ")\n",
        "\n",
        "print(Z_encoder_decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdDP3dyTae0z",
        "outputId": "b3eba086-319d-4d2d-ce19-70daa16b6f16"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.72697124 -3.13657083 -4.44877557  2.80038196]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z_encoder_decoder = layer_norm(Z_encoder_decoder + Z_self_attention)\n",
        "print(Z_encoder_decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvisJ7rMbDhS",
        "outputId": "ff55d349-2cbd-40a9-dbff-2134319aa319"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.9294116  -0.50335337 -1.39456724  0.96850901]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = np.random.randn(4, 8)\n",
        "W2 = np.random.randn(8, 4)\n",
        "b1 = np.random.randn(8)\n",
        "b2 = np.random.randn(4)\n",
        "\n",
        "output = layer_norm(feed_forward(Z_encoder_decoder, W1, b1, W2, b2) + Z_encoder_decoder)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-NfL8onbWV-",
        "outputId": "bcfd7438-2688-4292-debc-9cd7b505cb4c"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.27712579  0.47602231 -1.45532843  1.2564319 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_embedding = 4\n",
        "d_key = d_value = d_query = 3\n",
        "d_feed_forward = 8\n",
        "n_attention_heads = 2\n",
        "encoder_output = np.array([[-1.5, 1.0, -0.8, 1.5], [1.0, -1.0, -0.5, 1.0]])\n",
        "\n",
        "def decoder_block(\n",
        "    x,\n",
        "    encoder_output,\n",
        "    WQs_self_attention, WKs_self_attention, WVs_self_attention,\n",
        "    WQs_ed_attention, WKs_ed_attention, WVs_ed_attention,\n",
        "    W1, b1, W2, b2,\n",
        "):\n",
        "    # То же, что и раньше\n",
        "    Z = multi_head_attention(\n",
        "        x, WQs_self_attention, WKs_self_attention, WVs_self_attention\n",
        "    )\n",
        "    Z = layer_norm(Z + x)\n",
        "\n",
        "    # Основное различие заключается в следующих трёх строках!\n",
        "    Z_encoder_decoder = multi_head_encoder_decoder_attention(\n",
        "        encoder_output, Z, WQs_ed_attention, WKs_ed_attention, WVs_ed_attention\n",
        "    )\n",
        "    Z_encoder_decoder = layer_norm(Z_encoder_decoder + Z)\n",
        "\n",
        "    # То же, что и раньше\n",
        "    output = feed_forward(Z_encoder_decoder, W1, b1, W2, b2)\n",
        "    return layer_norm(output + Z_encoder_decoder)\n",
        "\n",
        "def random_decoder_block(x, encoder_output):\n",
        "    # Просто несколько произвольных инициализаций\n",
        "    WQs_self_attention = [\n",
        "        np.random.randn(d_embedding, d_query) for _ in range(n_attention_heads)\n",
        "    ]\n",
        "    WKs_self_attention = [\n",
        "        np.random.randn(d_embedding, d_key) for _ in range(n_attention_heads)\n",
        "    ]\n",
        "    WVs_self_attention = [\n",
        "        np.random.randn(d_embedding, d_value) for _ in range(n_attention_heads)\n",
        "    ]\n",
        "\n",
        "    WQs_ed_attention = [\n",
        "        np.random.randn(d_embedding, d_query) for _ in range(n_attention_heads)\n",
        "    ]\n",
        "    WKs_ed_attention = [\n",
        "        np.random.randn(d_embedding, d_key) for _ in range(n_attention_heads)\n",
        "    ]\n",
        "    WVs_ed_attention = [\n",
        "        np.random.randn(d_embedding, d_value) for _ in range(n_attention_heads)\n",
        "    ]\n",
        "\n",
        "    W1 = np.random.randn(d_embedding, d_feed_forward)\n",
        "    b1 = np.random.randn(d_feed_forward)\n",
        "    W2 = np.random.randn(d_feed_forward, d_embedding)\n",
        "    b2 = np.random.randn(d_embedding)\n",
        "\n",
        "\n",
        "    return decoder_block(\n",
        "        x, encoder_output,\n",
        "        WQs_self_attention, WKs_self_attention, WVs_self_attention,\n",
        "        WQs_ed_attention, WKs_ed_attention, WVs_ed_attention,\n",
        "        W1, b1, W2, b2,\n",
        "    )\n",
        "def decoder(x, decoder_embedding, n=6):\n",
        "    for _ in range(n):\n",
        "        x = random_decoder_block(x, decoder_embedding)\n",
        "    return x\n",
        "\n",
        "\n",
        "dec_enc_out=decoder(E, encoder_output)\n",
        "print(dec_enc_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyRbNCEmbz-g",
        "outputId": "2be87963-db37-4a58-e681-3756188c4765"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.87871785  1.67300064 -0.63534245 -0.15894034]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def linear(x, W, b):\n",
        "    return np.dot(x, W) + b\n",
        "\n",
        "x = linear([1, 0, 1, 0], np.random.randn(4, 10), np.random.randn(10))\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xwutksUcW3z",
        "outputId": "58d91269-718a-45ba-f4b3-9af5ae67312d"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.25100542 -1.31979351  1.30854114 -2.98388191  1.71615877  1.2947306\n",
            " -1.85872236 -1.10394769 -2.19843987 -2.7801584 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    exp_x = np.exp(x)\n",
        "    return exp_x / np.sum(exp_x, keepdims=True)\n",
        "\n",
        "print(softmax(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbvXx18JdTB0",
        "outputId": "a6715604-a123-4c18-bbf9-c8f28ae39e51"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.13673568 0.54152865 0.01384858 0.01070712 0.05474137 0.00209842\n",
            " 0.12425241 0.06915061 0.04144783 0.00548934]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = [\n",
        "    \"hello\",\n",
        "    \"mundo\",\n",
        "    \"world\",\n",
        "    \"how\",\n",
        "    \"?\",\n",
        "    \"EOS\",\n",
        "    \"SOS\",\n",
        "    \"a\",\n",
        "    \"hola\",\n",
        "    \"c\",\n",
        "]\n",
        "embedding_reps = np.random.randn(10, 4)\n",
        "vocabulary_embeddings = {\n",
        "    word: embedding_reps[i] for i, word in enumerate(vocabulary)\n",
        "}\n",
        "print(vocabulary_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uyWJ6HPfB7E",
        "outputId": "b0fdac62-147e-4da5-9a60-229606cb3625"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'hello': array([-0.35165666,  1.65043144,  0.53797996, -0.42548313]), 'mundo': array([ 1.09150189,  0.96717746, -1.31796533,  1.38434922]), 'world': array([0.94496363, 1.03021505, 0.77656003, 0.06628513]), 'how': array([-1.77186851,  0.40955654, -1.27333805, -0.15955161]), '?': array([ 0.79337803, -1.3616285 ,  0.20850618, -0.83816508]), 'EOS': array([-0.23736802, -0.30935027, -0.51520345,  0.52854977]), 'SOS': array([ 1.232424  , -0.59783195,  0.00913838,  0.61834051]), 'a': array([1.33523653, 0.00164602, 1.00973062, 0.92236917]), 'hola': array([ 0.07742248, -1.74372511,  0.68177239, -2.40341855]), 'c': array([1.34421134, 0.494023  , 1.06078546, 0.43702237])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(input_sequence, max_iters=3):\n",
        "    # Сначала мы кодируем входные данные в эмбеддинги\n",
        "    # Для простоты мы пропустим этап позиционного кодирования\n",
        "    embedded_inputs = [\n",
        "        vocabulary_embeddings[token] for token in input_sequence\n",
        "    ]\n",
        "    print(\"Embedding representation (encoder input)\", embedded_inputs)\n",
        "\n",
        "    # Затем генерируем описание эмбеддинга\n",
        "    encoder_output = encoder(embedded_inputs)\n",
        "    print(\"Embedding generated by encoder (encoder output)\", encoder_output)\n",
        "\n",
        "    # Инициализируем выходные данные декодера эмбеддингом начального токена\n",
        "    sequence_embeddings = [vocabulary_embeddings[\"SOS\"]]\n",
        "    output = \"SOS\"\n",
        "\n",
        "    # Случайные матрицы для линейного слоя\n",
        "    W_linear = np.random.randn(d_embedding, len(vocabulary))\n",
        "    b_linear = np.random.randn(len(vocabulary))\n",
        "\n",
        "    # Мы ограничиваем количество этапов декодинга, чтобы избежать слишком последовательностей без EOS\n",
        "    for i in range(max_iters):\n",
        "        # Этап декодера\n",
        "        decoder_output = decoder(sequence_embeddings, encoder_output)\n",
        "\n",
        "        # Используем для предсказания только последние выходные данные\n",
        "        logits = linear(decoder_output[-1], W_linear, b_linear)\n",
        "        # Обёртываем логиты в список, потому что softmax нужны пакеты/2D-массив\n",
        "        probs = softmax([logits])\n",
        "\n",
        "        # Получаем наиболее вероятный следующий токен\n",
        "        next_token = vocabulary[np.argmax(probs)]\n",
        "        sequence_embeddings.append(vocabulary_embeddings[next_token])\n",
        "        output += \" \" + next_token\n",
        "\n",
        "        print(\n",
        "            \"Iteration\", i,\n",
        "            \"next token\", next_token,\n",
        "            \"with probability of\", np.max(probs),\n",
        "        )\n",
        "\n",
        "        # Если следующий токен последний, то возвращаем последовательность\n",
        "        if next_token == \"EOS\":\n",
        "            return output\n",
        "\n",
        "    return output, sequence_embeddings"
      ],
      "metadata": {
        "id": "c91CxveMfz3X"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate([\"hello\", \"world\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeBcf3xKf_JY",
        "outputId": "fdde6d9f-698a-4129-9e54-4ad615cf9283"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding representation (encoder input) [array([-0.35165666,  1.65043144,  0.53797996, -0.42548313]), array([0.94496363, 1.03021505, 0.77656003, 0.06628513])]\n",
            "Embedding generated by encoder (encoder output) [[ 1.27123538  0.62012382 -1.27032215 -0.62103704]\n",
            " [ 1.24332031  0.639001   -1.31147398 -0.57084733]]\n",
            "Iteration 0 next token how with probability of 0.6142360961970552\n",
            "Iteration 1 next token EOS with probability of 0.25584905226910837\n",
            "SOS how EOS\n"
          ]
        }
      ]
    }
  ]
}